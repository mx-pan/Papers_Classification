**题目**
Evolutionary game dynamics of multi-agent cooperation driven by self-learning
**关键字**
Multi-agent cooperation; Evolutionary game dynamics; self-learning; self-evaluation
**摘要**
Multi-agent cooperation problem is a fundamental issue in the coordination control field. Individuals achieve a common task through association with others or division of labor. Evolutionary game dynamics offers a basic framework to investigate how agents self-adaptively switch their strategies in accordance with various targets, and also the evolution of their behaviors. In this paper, we analytically study the strategy evolution in a multiple player game model driven by self-learning. Self-learning dynamics is of importance for agent strategy updating yet seldom analytically addressed before. It is based on self-evaluation, which applies to distributed control. We focus on the abundance of different strategies (behaviors of agents) and their oscillation (frequency of behavior switching). We arrive at the condition under which a strategy is more abundant over the other under weak selection limit. Such condition holds for any finite population size of N3, thus it fits for the systems with finite agents, which has notable advantage over that of pairwise comparison process. At certain states of evolutionary stable state, there exists ping-pong effect with stable frequency, which is not affected by aspirations. Our results indicate that self-learning dynamics of multi-player games has special characters. Compared with pairwise comparison dynamics and Moran process, it shows different effect on strategy evolution, such as promoting cooperation in collective risk games with large threshold.