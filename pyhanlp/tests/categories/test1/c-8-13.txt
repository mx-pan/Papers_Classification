**题目**
面向智能移动监控辅助的可穿戴视觉研究
**关键字**
可穿戴视觉,可穿戴计算,移动计算,集成智能,监控系统
**摘要**
“持续辅助”和“增强”是可穿戴计算“人机合一”、“以人为中心”理念的核心内涵。近年来,可持续辅助人,增强人类感能、体能、智能的可穿戴计算技术和原型系统得到了快速发展,显示出了巨大的市场潜力和技术生命力。可对人进行视觉辅助和实时视觉增强的可穿戴视觉(Wearable Vision)便是这样一个新兴的研究方向和备受关注的前沿技术,它不仅涉及到可穿戴计算、机器视觉、人工智能、模式识别,也涉及到认知科学、心理学等多学科高技术的交叉和结晶。可穿戴视觉强调以与人类近似的“第一人视角”随时随地捕获穿戴者自己或周围环境的图像信息,利用计算机视觉技术给予实时分析和处理,最终形成对环境中人、事、物的综合理解,从而为穿戴者提供及时的视觉辅助和有意义的行动规划。
随着监控技术的应用和发展,以固定摄像机为代表的视频监控系统已经充斥着大部分公共场所,但目前大多仍以录制视频图像和事后调用取证为主,不能胜任实时主动监控的需要,尤其对公共场所中突发犯罪事件的防控。因此,重要的公共场所仍然需要由人来进行巡逻防控和识别犯罪。另据研究表明,长时间、高注意力的视觉观察是极其消耗生物能量的脑力活动,极易产生视觉疲劳、反应迟钝、记忆减弱等不良精神状态,人在此状态下很可能会错过有价值的视觉信息。如果能为从事高强度视觉任务的巡逻者提供具有可持续视觉辅助功能,增强其视觉判断能力的可穿戴视觉系统,将大大提高巡逻防控效率和监控能力。
可穿戴视觉系统随人移动,处于一个不可控的动态复杂环境中,在视觉图像处理与识别中面临着许多特殊的挑战与难题。本文是在目前国内外研究成果的基础上,通过研发人巡逻时用到的智能移动监控辅助系统原型来对可穿戴视觉的关键问题进行研究。主要贡献和创新点可概括如下:
①在研究人机集成智能理论、计算机视觉理论及可穿戴智能的基础上,提出了适用于可穿戴计算环境和移动监控任务的可穿戴人机协同视觉体系WICVA,明确了实现该体系的两个关键模块:可穿戴视觉决策和视觉辅助的动态调度机制。可穿戴视觉决策为WearVision克服多变不可控复杂环境带来的识别影响提供了可行的应用框架,保证了WearVision在进行视觉信息处理时的有效性、选择性和智能性,是集成智能学的新发展和新应用。同时对WICVA中动态辅助机制进行了研究,提出了基于扩展模糊有色Petri网的动态辅助调度算法,使之能根据上下文自动调用相应辅助服务于巡逻者。WICVA是在人-机各自的视觉系统特点上进行取长补短、相互辅助,可用于指导可穿戴视觉辅助系统的应用设计,并为人机协同识别提供理论支撑。在该体系的指导下我们研发了可穿戴智能监控辅助系统原型iWearSA平台。
②为实现WICVA中的人机共同感知,提出了一种人视觉注意力驱动的兴趣场景和候选目标图像捕获方法。该方法充分利用人视觉注意力的优点,结合分块场景匹配计算法和运动区域估计法识别出穿戴者的关注行为,以及主动注意和被动注意状态,因此可以有选择性地采集穿戴者感兴趣场景,避免采集和处理大量无意义的视觉图像,为可穿戴计算机节约了平台资源;同时,为了进一步明确运动目标区域,研究了可穿戴摄像机条件下的运动目标分割问题,提出了一种基于运动全景补偿的运动目标检测算法,该方法既弥补了WearVision视场较小的弱点,用于生成连续视场范围内的全景图像,又可对抖动图像序列进行稳像处理,输出稳像视频和运动目标区域,协助穿戴者进行更精确的运动目标搜索与定位。
③为实现WICVA中对感知图像的选择性处理,提出一种基于图像质量评价优先度的择优处理策略,对该策略中的关键技术模糊图像检测技术进行了研究,给出了基于概率支持向量机的运动模糊图像分类方法,该方法能快速检测出采集图像是否存在运动模糊并估计模糊的程度,通过预设的质量处理策略筛选出合适质量的图像,既解决了可穿戴视觉系统在图像处理中的选择性和有效性,又可用于辅助提示穿戴者对不合格图像进行重拍。
④对WICVA中的人机协同识别进行了探索性研究,以人脸追逃为实验背景,提出了一种可修正人眼检测定位错误的方法,该方法针对已有的Adaboost算法及人眼检测分类器进行人眼检测后的错误定位问题,能快速修正人眼的漏检、检误问题,提高了在不可控环境中的双眼定位准确率,使得分类器对任何可穿戴场景都有良好的通用性,提高了复杂背景和随意运动摄像机条件下的人脸检测率。最后,提出了基于单训练样本和变归一化尺度的快速人脸识别算法,按“机粗人精”的人机协同识别顺序进行了室内外实验,即由WearVision先快速识别出候选者,再由人进行精确识别。实验证明人机协同识别比单独用人识别或者单独用机器识别的准确率更好,更符合实际应用。
